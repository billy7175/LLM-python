"""Ollama Provider í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import sys
from src.llm.ollama_provider import OllamaProvider


def test_ollama():
    """Ollama Provider ê¸°ë³¸ í…ŒìŠ¤íŠ¸"""
    print("Testing Ollama Provider...")
    print("-" * 50)
    
    # Provider ìƒì„±
    provider = OllamaProvider(model="llama3")
    
    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€
    messages = [
        {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨íˆ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."}
    ]
    
    try:
        print("Sending request to Ollama...")
        response = provider.generate(messages, temperature=0.7)
        
        print("\nâœ… Success!")
        print("\nResponse:")
        print("-" * 50)
        print(response)
        print("-" * 50)
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        print("\nğŸ’¡ Make sure Ollama is running:")
        print("   ollama serve")
        print("   ollama pull llama3")
        sys.exit(1)


if __name__ == "__main__":
    test_ollama()

